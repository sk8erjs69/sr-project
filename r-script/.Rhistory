## same and the slope of the linear model is
## equal to the difference between means
#################################################
# compare p-values
result$p.value
summary(fit1)
# compare difference in means
result$estimate[2] - result$estimate[1]
fit1$coefficients
#######################################################
## We can also fit a model using "indicator" variables
## and without an intercept
#######################################################
######################################################
# We can code our qualitative explanatory variable
# in several ways
######################################################
drinking.status = factor(survey$Alcohol == 0)
levels(drinking.status) = c("Drinker", "NonDrinker")
groups = levels(drinking.status)
######################################################
# Treatment contrasts: code reflects change from a
# reference group
######################################################
# NonDrinker (1st level) = 0, Drinker (2nd level) = 1
contr.treatment(groups)
fit.treatment = lm(survey$College.GPA ~ drinking.status,
contrasts = contr.treatment(2))
summary(fit.treatment)
## difference in means is equal to slope ##
coefficients(fit.treatment)[2]
######################################################
# Sum contrasts: coefficients add up to 0
######################################################
# NonDrinker (1st level) = -1, Drinker (2nd level) = +1
contr.sum(groups)
fit.sum = lm(survey$College.GPA ~ drinking.status,
contrasts = contr.sum(groups))
# What does the slope represent? And why? #
coefficients(fit.sum)[2]
###################################################
# Use indicator (1 or 0) for group1 AND group2
# (this model has 2 'slope' variables and no
# 'intercept')
###################################################
fit.indicator = lm(survey$College.GPA ~ -1 + drinking.status)
#####################################################
# The p-values for each coefficient (b) test against
# H0: b = 0
# which is not what we want.
# The test of interest is whether b1-b2 = 0, which
# could be calculated manually or using additional
# packages (we will not worry about this for now)
# This is the formulation that will be used to test
# all probes for differential expression
#####################################################
################################################################
# Finding differentially expressed genes
################################################################
################################################################
# Relationship btwn linear model and t-test
################################################################
## Compare the GPAs of drinkers to non-drinkers in our class ##
survey = read.csv("http://bioinformatics.easternct.edu/CSC-315/our_survey.csv")
s = split(survey$College.GPA, survey$Alcohol==0)
drinkers = s[[1]] ## 1st group corresponds to survey$Alcohol > 0 being FALSE
nondrinkers = s[[2]] ## 2nd group corresponds to survey$Alcohol > 0 being TRUE
## how we have called t-test previously, which assumes unequal variances ##
t.test(drinkers, nondrinkers)
## we can assume equal variances
result = t.test(drinkers, nondrinkers, var.equal = TRUE)
####################################################
# let's formulate this in terms of a linear model
# We want to predict GPA based on drinking status
####################################################
non.drinker = as.integer(survey$Alcohol == 0)
plot(non.drinker, survey$College.GPA, pch = 19,
xlab = "Non-Drinker (0 = Yes, 1 = No",
ylab = "College GPA")
fit1 = lm(survey$College.GPA ~ non.drinker)
abline(fit1, col = "red")
#################################################
# Now compare p-values of t-test to the p-values
# from the linear model which tests against
# H0: b = 0 in y = a + bx
# HA: b != 0
#################################################
#################################################
## These analyses are the same! P-values are the
## same and the slope of the linear model is
## equal to the difference between means
#################################################
# compare p-values
result$p.value
summary(fit1)
# compare difference in means
result$estimate[2] - result$estimate[1]
fit1$coefficients
#######################################################
## We can also fit a model using "indicator" variables
## and without an intercept
#######################################################
######################################################
# We can code our qualitative explanatory variable
# in several ways
######################################################
drinking.status = factor(survey$Alcohol == 0)
levels(drinking.status) = c("Drinker", "NonDrinker")
groups = levels(drinking.status)
######################################################
# Treatment contrasts: code reflects change from a
# reference group
######################################################
# NonDrinker (1st level) = 0, Drinker (2nd level) = 1
contr.treatment(groups)
fit.treatment = lm(survey$College.GPA ~ drinking.status,
contrasts = contr.treatment(2))
summary(fit.treatment)
## difference in means is equal to slope ##
coefficients(fit.treatment)[2]
######################################################
# Sum contrasts: coefficients add up to 0
######################################################
# NonDrinker (1st level) = -1, Drinker (2nd level) = +1
contr.sum(groups)
fit.sum = lm(survey$College.GPA ~ drinking.status,
contrasts = contr.sum(groups))
# What does the slope represent? And why? #
coefficients(fit.sum)[2]
###################################################
# Use indicator (1 or 0) for group1 AND group2
# (this model has 2 'slope' variables and no
# 'intercept')
###################################################
fit.indicator = lm(survey$College.GPA ~ -1 + drinking.status)
#####################################################
# The p-values for each coefficient (b) test against
# H0: b = 0
# which is not what we want.
# The test of interest is whether b1-b2 = 0, which
# could be calculated manually or using additional
# packages (we will not worry about this for now)
# This is the formulation that will be used to test
# all probes for differential expression
#####################################################
###############################################################
# k-nearest neighbor (KNN) example
###############################################################
###############################################################
# Let's get the GSE1297 data again (modified from limma.R)
###############################################################
library(GEOquery)
GSE1297 = getGEO("GSE1297")
GSE1297
###########################################################
# Pull out gene expression data and pheno type data
###########################################################
# expression data must be logged -- see limma.R
GSE1297.expr = exprs(GSE1297[[1]])
GSE1297.expr = log2(GSE1297.expr)
GSE1297.p = pData(GSE1297[[1]])
################################################################
# Finding differentially expressed genes between males and
# females
################################################################
library(limma)
gender = as.character(GSE1297.p$characteristics_ch1.1)
levels(gender) = c("Female", "Male")
design = model.matrix(~0+gender)
colnames(design)
colnames(design) = c("Female", "Male")
## limma package fits a linear model to each row of the expression matrix ##
fit = lmFit(GSE1297.expr, design)
## Contrasts need to match column names of design matrix ##
contrast.matrix <- makeContrasts(Female - Male,levels=design)
## fit model based on contrasts (e.g., Female - Male)
fit = contrasts.fit(fit, contrast.matrix)
# calculate moderated t-statistics by moderating standard errors
# toward a common value, which makes answers more robust
fit = eBayes(fit)
## get top probes, sorted by p-value (gives top 10 genes by default)
tt.05 = topTable(fit,sort.by = "p", p.value = 0.05, number = nrow(GSE1297.expr))
##############################################################################
# In classification problems, it is often desirable to scale each probe,
# so that no single probe has a dominating effect. Below is an example
##############################################################################
#####################################################
# prints Euclidian distance matrix and plots cluster
#####################################################
plot.clust <-function(x) {
d = dist(t(x))
print(d)
h = hclust(d)
plot(h)
}
r = c(1.1, 2, 3)
M = rbind(r,r,r,r)
colnames(M) = c("A","B","C")
M
# A and B are the closest
plot.clust(M)
# if a probe with large expression is added, A and C are the closest
M = rbind(M, c(10,15,10))
M
plot.clust(M)
# scale each row
row.scale <-function(x) {
x.scale = t(scale(t(x)))
return(x.scale)
}
# with row scaling, A and B are the most similar
M.scale = row.scale(M) # scale each row
plot.clust(M.scale)
###############################################################
## back to microarray data
#  Visualization of two probes
###############################################################
## get probes that are differentially expressed
m = match(rownames(tt.05), rownames(GSE1297.expr))
X = GSE1297.expr[m,]
col.gender = as.integer(as.factor(gender))
col.gender = c("pink", "blue")[col.gender]
plot(X[1,], X[2,], col = col.gender, pch = 19, main = "top 2 probes")
X.scale = row.scale(X)
plot(X.scale[1,], X.scale[2,], col = col.gender, pch = 19, main = "top 2 probes, scaled")
###################################################################
# Let's predict the gender of each individual, using the 12 probes
# with FDR < 5%
# Note that knn requires samples in rows and features in columns
###################################################################
library(class) # required for knn
#######################################
# predict the gender of the 1st sample
#######################################
i.test = 1
# remove test sample from training data
X.train = t(X.scale[,-i.test])
Y.train = gender[-i.test]
# isolate test sample so we can classify it
X.test = t(X.scale[,i.test, drop = FALSE])  # drop maintains the dimensions
Y.test = gender[i.test]
## make prediction, using k = 3
p.test = knn(X.train, X.test, Y.train, k = 3)
p.test
Y.test
###################################################################
# Leave one out cross-validation:
# for each sample, predict its class after removing it from the
# training set. Use knn.cv function
###################################################################
preds = knn.cv(t(X.scale), gender, k = 3)
table(predicted = preds, true = gender)
# overall accuracy #
sum(preds == gender) / length(gender)
# classifiers may appear accurate because of imbalances in the data
# therefore, balanced accuracy (mean accuracy across groups)
# is often preferred
balanced.accuracy <-function(predicted, true) {
t = table(predicted = predicted, true = true)
if (nrow(t) != 2) {
stop("only 1 row in accuracy table")
}
acc = diag(t) / colSums(t)
print(acc)
mean(acc)
}
balanced.acc = balanced.accuracy(preds, gender)
balanced.acc
View(M)
row.scale <-function(x) {
x.scale = t(scale(t(x)))
return(x.scale)
}
# with row scaling, A and B are the most similar
M.scale = row.scale(data1) # scale each row
plot.clust(M.scale)
View(M.scale)
plot.clust(data1)
XXX.scale = row.scale(data1) # scale each row
plot.clust(XXX.scale)
colnames(XXX.scale) = data1$Gene.Symbol
XXX.scale = row.scale(data1) # scale each row
plot.clust(XXX.scale)
plot.clust(data1)
colnames(XXX.scale) = data1$Gene.Symbol
XXX.scale = row.scale(data1[2:4]) # scale each row
plot.clust(XXX.scale)
colnames(XX.scale) = data1[2:4]
XX.scale = row.scale(data1$Gene.Symbol) # scale each row
plot.clust(XX.scale)
colnames(XX.scale) = data1[2:4]
XX.scale = row.scale(data1$Gene.Symbol) # scale each row
colnames(XX.scale) = data1[2:4]
colnames(XXX.scale) = data1[2:4]
XXX.scale = row.scale(data1$Gene.Symbol) # scale each row
plot.clust(XXX.scale)
colnames(XXX.scale) = data1[2:4]
View(XXX.scale)
hclust(data1)
dist(t(data1))
data = read.csv("~/GitHub/sr-project/big-data/matrix.csv")
data1 = data.frame(data[data$Prostate.Count!=0,])
data1 = data.frame(data1[data1$Lung.Count!=0,])
data1 = data.frame(data1[data1$Brain.Count!=0,])
# scale each row
row.scale <-function(x) {
x.scale = t(scale(t(x)))
return(x.scale)
}
colnames(XXX.scale) = data1$Gene.Symbol
XXX.scale = row.scale(data1[2:4]) # scale each row
plot.clust(XXX.scale)
colnames(XXX.scale) = data1[2:4]
XXX.scale = row.scale(data1$Gene.Symbol) # scale each row
plot.clust(XXX.scale)
colnames(XXX.scale) = data1$Gene.Symbol
XXX.scale = row.scale(data1[2:4]) # scale each row
plot.clust(XXX.scale)
data.sum = apply(as.integer(data),1,sum)
data2 = data.frame[data.sum, row.names = data[0,]]
pct = round(data.sum/sum(data.sum) * 100)
lbls <- paste(data[0,],pct)
lbls <- paste(pct,"%",sep="") # ad % to labels
pie(data.sum,labels = lbls,main="Word Proportions over 3 documents")
data.sum = apply(as.integer(data1),1,sum)
data.sum = apply(as.integer(data1),2,sum)
data.sum = apply(as.integer(data1[2:4]),1,sum)
data[2:4]
data1[2:4]
data.sum = apply(data1[2:4],1,sum)
data.sum
data.sum = apply(as.integer(data1[2:4]),1,sum)
data2 = data.frame[data.sum, row.names = data1[0,]]
pct = round(data.sum/sum(data.sum) * 100)
lbls <- paste(data[0,],pct)
lbls <- paste(pct,"%",sep="") # ad % to labels
pie(data.sum,labels = lbls,main="Word Proportions over 3 documents")
data1 = data.frame(data[data$Prostate.Count>=3,])
data1 = data.frame(data1[data1$Lung.Count>=3,])
data1 = data.frame(data1[data1$Brain.Count>=3,])
data.sum = apply(as.integer(data1[2:4]),1,sum)
data2 = data.frame[data.sum, row.names = data1[0,]]
pct = round(data.sum/sum(data.sum) * 100)
lbls <- paste(data[0,],pct)
lbls <- paste(pct,"%",sep="") # ad % to labels
pie(data.sum,labels = lbls,main="Word Proportions over 3 documents")
data.sum = apply(as.integer(data1[2:4]),1,sum)
data2 = data.frame[data.sum, row.names = data1[0,]]
pct = round(data.sum/sum(data.sum) * 100)
lbls <- paste(data[0,],pct)
lbls <- paste(pct,"%",sep="") # ad % to labels
pie(data.sum,labels = lbls,main="Word Proportions over 3 documents")
data.sum[1:5]
data2
data2 = data.frame[data.sum, row.names = data1[0,]]
data.sum = apply(as.integer(data1[2:4]),1,sum)
data1 = data.frame(data[data$Prostate.Count>=3,])
data1 = data.frame(data1[data1$Lung.Count>=3,])
data1 = data.frame(data1[data1$Brain.Count>=3,])
data.sum = apply(as.integer(data1[2:4]),1,sum)
data.sum = apply(data1[2:4],1,sum)
pct = round(data.sum/sum(data.sum) * 100)
lbls <- paste(data1[0,],pct)
lbls <- paste(pct,"%",sep="") # ad % to labels
pie(data.sum,labels = lbls,main="Word Proportions over 3 documents")
data2 = data.frame[data.sum, row.names = data1[0,]]
data2 = data.frame(data.sum, row.names = data1[0,])
data.sum
length(data.sum)
length(data1)
data1
data2 = data.frame(data.sum, row.names = data1[0])
data1[0]
data[0,]
data[1]
data2 = data.frame(data.sum, row.names = data1[1])
row.names = data1[1]
pie(data1)
pie(data1[2:4])
data1[2:4]
pie(data1[2:4])
pie(data1[2:4]/sum(data[2:4]))
data1[2:4]/sum(data1[2:4])
pie(data1[2:4]/sum(data1[2:4]))
pie(data1[2:4]/sum(data1[2:4]))
pie(data1[2:4]/sum(data1[2:4])*100)
pie(abs(data1[2:4]/sum(data1[2:4])*100))
data1[2:4]/sum(data1[2:4])*100
sum(data[2:4])
data.sum = apply(data1[2:4],1,sum)
data.sum
data.sum
data.sum
data.sum[1]
data1[1]
data1[,1]
data[,222]
data[222]
data[,5]
data1[[1]]
data1[[5]]
data[1,]
data1[1,]
data1[,2:4]
data.sum = apply(data1[,2:4],1,sum)
data2 = data.frame(data.sum, row.names = data1[1])
pct = round(data.sum/sum(data.sum) * 100)
lbls <- paste(data1[0,],pct)
lbls <- paste(pct,"%",sep="") # ad % to labels
pie(data.sum,labels = lbls,main="Word Proportions over 3 documents")
data.sum/sum(data.sum) * 100
# get data from csv file
data = read.csv("~/GitHub/sr-project/big-data/matrix.csv")
#remove insignificant values
data1 = data.frame(data[data$Prostate.Count>=3,])
data1 = data.frame(data1[data1$Lung.Count>=3,])
data1 = data.frame(data1[data1$Brain.Count>=3,])
#create and transpose matrix for fisher test
m = matrix(c(data1$Prostate.Count,data1$Lung.Count,data1$Brain.Count), ncol = 3, byrow = FALSE)
m= t(m)
#fisher test function
f <- function(r){
x = r[1]
y = r[2]
z = r[3]
mm = matrix(c(x,20000-x,
y, 20000 - y,
z, 20000 - z ),nrow = 3, byrow = TRUE)
f = fisher.test(mm, workspace = 400000,hybrid = TRUE)
return (f$p.value)
}
#apply fisher test to entire matrix
fisher.p = apply(m,2,f)
#add back gene symbol names and pull out top 5 genes based on fisher.p value
fisher.frame = data.frame(data1$Gene.Symbol, fisher.p)
fisher.frame = fisher.frame[order(-fisher.frame$fisher.p),]
mtch = match(fisher.frame$data1.Gene.Symbol[1:5],data1$Gene.Symbol)
data1[mtch,]
#ATTEMPTED BOXPLOT NoT SURE IF THIS IS WORKING RIGHT
boxplot(data1[mtch,2:4])
#Pull out bottom five genes
fisher.frame = fisher.frame[order(fisher.frame$fisher.p),]
mtch = match(fisher.frame$data1.Gene.Symbol[1:5],data1$Gene.Symbol)
data1[mtch,]
#plot shows extreme differences between hits across these
barplot(t(as.matrix(data1[mtch,2:4])),xlab = "Gene Symbol",
col =c("red","green","blue"),names.arg = data[mtch,1], legend=colnames(data1[,2:4]), beside=TRUE)
#function for clustering
plot.clust <-function(x) {
d = dist(t(x))
print(d)
h = hclust(d)
plot(h)
}
#CLuster shows which cancer types are most similar
plot.clust(data1[,2:4])
#TODO: POSSIBLE CLUSTER TO SHOW COMPARISONS OF GENES
boxplot(data1[mtch,2:4])
data = read.csv("~/GitHub/sr-project/big-data/matrix.csv")
#remove insignificant values
data1 = data.frame(data[data$Prostate.Count>=3,])
data1 = data.frame(data1[data1$Lung.Count>=3,])
data1 = data.frame(data1[data1$Brain.Count>=3,])
#create and transpose matrix for fisher test
m = matrix(c(data1$Prostate.Count,data1$Lung.Count,data1$Brain.Count), ncol = 3, byrow = FALSE)
m= t(m)
#fisher test function
f <- function(r){
x = r[1]
y = r[2]
z = r[3]
mm = matrix(c(x,20000-x,
y, 20000 - y,
z, 20000 - z ),nrow = 3, byrow = TRUE)
f = fisher.test(mm, workspace = 400000,hybrid = TRUE)
return (f$p.value)
}
#apply fisher test to entire matrix
fisher.p = apply(m,2,f)
f <- function(r){
x = r[1]
y = r[2]
z = r[3]
mm = matrix(c(x,20000-x,
y, 20000 - y,
z, 20000 - z ),nrow = 3, byrow = TRUE)
f = fisher.test(mm, workspace = 800000,hybrid = TRUE)
return (f$p.value)
}
fisher.p = apply(m,2,f)
fisher.frame = data.frame(data1$Gene.Symbol, fisher.p)
fisher.frame = fisher.frame[order(-fisher.frame$fisher.p),]
mtch = match(fisher.frame$data1.Gene.Symbol[1:5],data1$Gene.Symbol)
data1[mtch,]
#ATTEMPTED BOXPLOT NoT SURE IF THIS IS WORKING RIGHT
boxplot(data1[mtch,2:4])
#Pull out bottom five genes
fisher.frame = fisher.frame[order(fisher.frame$fisher.p),]
mtch = match(fisher.frame$data1.Gene.Symbol[1:5],data1$Gene.Symbol)
data1[mtch,]
#plot shows extreme differences between hits across these
barplot(t(as.matrix(data1[mtch,2:4])),xlab = "Gene Symbol",
col =c("red","green","blue"),names.arg = data[mtch,1], legend=colnames(data1[,2:4]), beside=TRUE)
#function for clustering
plot.clust <-function(x) {
d = dist(t(x))
print(d)
h = hclust(d)
plot(h)
}
#CLuster shows which cancer types are most similar
plot.clust(data1[,2:4])
